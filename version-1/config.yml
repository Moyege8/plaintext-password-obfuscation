# Bindplane Configuration File
# This is a sample configuration demonstrating multiple data sources and destinations

# Server Configuration
server:
  host: 0.0.0.0
  port: 3001
  secretKey: "your-secret-key-here"
  tlsConfig:
    cert: /etc/bindplane/certs/server.crt
    key: /etc/bindplane/certs/server.key

# Database Configuration
database:
  type: postgres
  connection:
    host: localhost
    port: 5432
    database: bindplane
    username: bindplane_user
    password: "your-database-password-here"
    sslMode: require

# Authentication Configuration
auth:
  type: ldap
  ldap:
    host: ad.company.com
    port: 636
    useTLS: true
    bindDN: "CN=bindplane-service,OU=Service Accounts,DC=company,DC=com"
    bindPassword: "your-active-directory-password-here"
    baseDN: "DC=company,DC=com"
    userFilter: "(&(objectClass=user)(sAMAccountName=%s))"
    groupFilter: "(&(objectClass=group)(member=%s))"
    adminGroup: "CN=Bindplane-Admins,OU=Groups,DC=company,DC=com"
    userGroup: "CN=Bindplane-Users,OU=Groups,DC=company,DC=com"

# Remote URL for configuration storage
remoteURL: https://config-repo.company.com/bindplane

# Telemetry Configuration
telemetry:
  enabled: true
  metrics:
    enabled: true
    port: 9090
  traces:
    enabled: true
    endpoint: http://jaeger-collector:14268/api/traces
  logs:
    enabled: true
    level: info
    outputPath: /var/log/bindplane/bindplane.log

# Data Sources Configuration
sources:
  # Prometheus Source
  - name: prometheus-metrics
    type: prometheus
    config:
      endpoint: http://prometheus-server:9090
      scrapeInterval: 30s
      username: prometheus_user
      password: "your-prometheus-password-here"
      tlsConfig:
        insecureSkipVerify: false
        certFile: /etc/bindplane/certs/prometheus-client.crt
        keyFile: /etc/bindplane/certs/prometheus-client.key

  # Active Directory Logs
  - name: active-directory-logs
    type: windows_event_log
    config:
      servers:
        - host: dc01.company.com
          username: "COMPANY\\log-collector"
          password: "your-ad-log-collector-password-here"
        - host: dc02.company.com
          username: "COMPANY\\log-collector"
          password: "your-ad-log-collector-password-here"
      channels:
        - Security
        - System
        - Application
        - "Directory Service"
      query: "*[System[(Level=1 or Level=2 or Level=3)]]"

  # MySQL Database Metrics
  - name: mysql-metrics
    type: mysql
    config:
      endpoint: mysql-server:3306
      username: monitoring_user
      password: "your-mysql-password-here"
      database: information_schema
      collectionInterval: 60s
      metrics:
        - mysql.connections
        - mysql.queries
        - mysql.slow_queries

  # Apache Web Server Logs
  - name: apache-logs
    type: apache
    config:
      accessLogPath: /var/log/apache2/access.log
      errorLogPath: /var/log/apache2/error.log
      hosts:
        - web01.company.com
        - web02.company.com
      username: log_collector
      password: "your-apache-ssh-password-here"

  # Kafka Metrics
  - name: kafka-metrics
    type: kafka
    config:
      brokers:
        - kafka01.company.com:9092
        - kafka02.company.com:9092
        - kafka03.company.com:9092
      username: kafka_monitor
      password: "your-kafka-password-here"
      saslMechanism: PLAIN
      securityProtocol: SASL_SSL
      topics:
        - application-logs
        - system-events

  # Redis Metrics
  - name: redis-metrics
    type: redis
    config:
      endpoint: redis.company.com:6379
      password: "your-redis-password-here"
      database: 0
      collectionInterval: 30s

  # Elasticsearch Logs
  - name: elasticsearch-logs
    type: elasticsearch
    config:
      endpoints:
        - https://es01.company.com:9200
        - https://es02.company.com:9200
      username: elastic_reader
      password: "your-elasticsearch-password-here"
      indices:
        - logs-*
        - metrics-*
      tlsConfig:
        insecureSkipVerify: false

# Data Destinations Configuration
destinations:
  # Splunk Destination
  - name: splunk-hec
    type: splunk_hec
    config:
      endpoint: https://splunk.company.com:8088/services/collector
      token: "your-splunk-hec-token-here"
      index: bindplane_metrics
      source: bindplane
      sourcetype: _json
      tlsConfig:
        insecureSkipVerify: false

  # Elasticsearch Destination
  - name: elasticsearch-output
    type: elasticsearch
    config:
      endpoints:
        - https://es-ingest01.company.com:9200
      username: elastic_writer
      password: "your-elasticsearch-output-password-here"
      index: bindplane-logs-%{+yyyy.MM.dd}
      pipeline: bindplane-pipeline

  # S3 Destination
  - name: s3-archive
    type: s3
    config:
      bucket: company-telemetry-archive
      region: us-east-1
      accessKeyId: "your-aws-access-key-id"
      secretAccessKey: "your-aws-secret-access-key"
      prefix: bindplane/logs/
      compression: gzip

  # Google Cloud Storage
  - name: gcs-backup
    type: gcs
    config:
      bucket: company-logs-backup
      projectId: company-project-id
      credentialsFile: /etc/bindplane/gcp-credentials.json
      prefix: bindplane/

# Pipeline Configuration
pipelines:
  - name: ad-to-splunk
    sources:
      - active-directory-logs
    processors:
      - type: filter
        config:
          include:
            severity: [error, warning, critical]
      - type: transform
        config:
          addFields:
            environment: production
            team: security
    destinations:
      - splunk-hec

  - name: metrics-to-elasticsearch
    sources:
      - prometheus-metrics
      - mysql-metrics
      - redis-metrics
      - kafka-metrics
    processors:
      - type: batch
        config:
          timeout: 10s
          maxSize: 1000
    destinations:
      - elasticsearch-output

  - name: logs-archive
    sources:
      - apache-logs
      - active-directory-logs
      - elasticsearch-logs
    destinations:
      - s3-archive
      - gcs-backup

# Resource Limits
resources:
  memoryLimit: 4Gi
  cpuLimit: 2000m
  diskLimit: 100Gi

# Retry Configuration
retry:
  enabled: true
  maxRetries: 3
  retryInterval: 5s
  backoffMultiplier: 2
